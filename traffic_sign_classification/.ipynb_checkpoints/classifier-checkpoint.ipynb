{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenhsu/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 14\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('$')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in reading X.h5. Processing all images...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with  h5py.File('X.h5') as hf: \n",
    "        X, y = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from X.h5\")\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")\n",
    "    root_dir = './../../LISA_TS/my_category'\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    print(all_img_paths)\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))\n",
    "            label = get_class(img_path)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%100 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "\n",
    "    with h5py.File('X.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
