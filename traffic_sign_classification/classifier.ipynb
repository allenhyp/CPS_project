{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenhsu/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 14\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('$')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in reading X.h5. Processing all images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenhsu/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/3939\n",
      "Processed 2000/3939\n",
      "Processed 3000/3939\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with  h5py.File('X.h5') as hf: \n",
    "        X, y = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from X.h5\")\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")\n",
    "    root_dir = 'training_set/'\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*.png'))\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))\n",
    "            label = get_class(img_path)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "    with h5py.File('X.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3151 samples, validate on 788 samples\n",
      "Epoch 1/30\n",
      "3151/3151 [==============================] - 1s 374us/step - loss: 0.0341 - acc: 0.9867 - val_loss: 0.0439 - val_acc: 0.9911\n",
      "Epoch 2/30\n",
      "3151/3151 [==============================] - 1s 351us/step - loss: 0.0348 - acc: 0.9870 - val_loss: 0.0257 - val_acc: 0.9937\n",
      "Epoch 3/30\n",
      "3151/3151 [==============================] - 1s 339us/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0261 - val_acc: 0.9949\n",
      "Epoch 4/30\n",
      "3151/3151 [==============================] - 1s 346us/step - loss: 0.0201 - acc: 0.9930 - val_loss: 0.0339 - val_acc: 0.9949\n",
      "Epoch 5/30\n",
      "3151/3151 [==============================] - 1s 348us/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.0324 - val_acc: 0.9924\n",
      "Epoch 6/30\n",
      "3151/3151 [==============================] - 1s 347us/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0350 - val_acc: 0.9898\n",
      "Epoch 7/30\n",
      "3151/3151 [==============================] - 1s 354us/step - loss: 0.0238 - acc: 0.9914 - val_loss: 0.0297 - val_acc: 0.9937\n",
      "Epoch 8/30\n",
      "3151/3151 [==============================] - 1s 365us/step - loss: 0.0193 - acc: 0.9937 - val_loss: 0.0375 - val_acc: 0.9937\n",
      "Epoch 9/30\n",
      "3151/3151 [==============================] - 1s 363us/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0398 - val_acc: 0.9911\n",
      "Epoch 10/30\n",
      "3151/3151 [==============================] - 1s 366us/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0526 - val_acc: 0.9911\n",
      "Epoch 11/30\n",
      "3151/3151 [==============================] - 1s 368us/step - loss: 0.0126 - acc: 0.9949 - val_loss: 0.0476 - val_acc: 0.9911\n",
      "Epoch 12/30\n",
      "3151/3151 [==============================] - 1s 357us/step - loss: 0.0107 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9911\n",
      "Epoch 13/30\n",
      "3151/3151 [==============================] - 1s 359us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 0.0387 - val_acc: 0.9924\n",
      "Epoch 14/30\n",
      "3151/3151 [==============================] - 1s 361us/step - loss: 0.0075 - acc: 0.9968 - val_loss: 0.0433 - val_acc: 0.9911\n",
      "Epoch 15/30\n",
      "3151/3151 [==============================] - 1s 334us/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0444 - val_acc: 0.9911\n",
      "Epoch 16/30\n",
      "3151/3151 [==============================] - 1s 365us/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0472 - val_acc: 0.9911\n",
      "Epoch 17/30\n",
      "3151/3151 [==============================] - 1s 357us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0444 - val_acc: 0.9911\n",
      "Epoch 18/30\n",
      "3151/3151 [==============================] - 1s 340us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0460 - val_acc: 0.9911\n",
      "Epoch 19/30\n",
      "3151/3151 [==============================] - 1s 351us/step - loss: 0.0044 - acc: 0.9975 - val_loss: 0.0449 - val_acc: 0.9924\n",
      "Epoch 20/30\n",
      "3151/3151 [==============================] - 1s 359us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0410 - val_acc: 0.9937\n",
      "Epoch 21/30\n",
      "3151/3151 [==============================] - 1s 346us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0413 - val_acc: 0.9937\n",
      "Epoch 22/30\n",
      "3151/3151 [==============================] - 1s 349us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0416 - val_acc: 0.9937\n",
      "Epoch 23/30\n",
      "3151/3151 [==============================] - 1s 345us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0416 - val_acc: 0.9937\n",
      "Epoch 24/30\n",
      "3151/3151 [==============================] - 1s 348us/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.0418 - val_acc: 0.9937\n",
      "Epoch 25/30\n",
      "3151/3151 [==============================] - 1s 365us/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0420 - val_acc: 0.9937\n",
      "Epoch 26/30\n",
      "3151/3151 [==============================] - 1s 344us/step - loss: 0.0030 - acc: 0.9987 - val_loss: 0.0423 - val_acc: 0.9937\n",
      "Epoch 27/30\n",
      "3151/3151 [==============================] - 1s 346us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0426 - val_acc: 0.9937\n",
      "Epoch 28/30\n",
      "3151/3151 [==============================] - 1s 340us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0424 - val_acc: 0.9937\n",
      "Epoch 29/30\n",
      "3151/3151 [==============================] - 1s 344us/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0424 - val_acc: 0.9937\n",
      "Epoch 30/30\n",
      "3151/3151 [==============================] - 1s 342us/step - loss: 0.0048 - acc: 0.9978 - val_loss: 0.0426 - val_acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f28b4bd4ef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 30\n",
    "\n",
    "model.fit(X, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                    ModelCheckpoint('model.h5',save_best_only=True)]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allenhsu/.local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'testing_set/'\n",
    "X_test = []\n",
    "y_test = []\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*.png'))\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        X_test.append(img)\n",
    "        y_test.append(label)\n",
    "\n",
    "        if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9870967741935484\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
